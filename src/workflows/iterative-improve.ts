#!/usr/bin/env node
/**
 * Meta TestGen-LLM é£æ ¼çš„è¿­ä»£æ”¹è¿›æœºåˆ¶
 * 
 * å·¥ä½œæµç¨‹ï¼š
 * 1. ç”Ÿæˆæµ‹è¯•
 * 2. æ£€æŸ¥è´¨é‡ï¼ˆæ„å»ºã€é€šè¿‡ã€è¦†ç›–ç‡ï¼‰
 * 3. å¦‚æœä¸æ»¡è¶³æ ‡å‡† â†’ æ”¶é›†åé¦ˆ â†’ é‡æ–°ç”Ÿæˆ
 * 4. é‡å¤ç›´åˆ°ï¼šè¾¾åˆ°è´¨é‡æ ‡å‡† OR è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
 */

import { spawn, ChildProcess, StdioOptions } from 'node:child_process'
import { existsSync, readFileSync, writeFileSync } from 'node:fs'
import { join, dirname } from 'node:path'
import { fileURLToPath } from 'node:url'

const __filename = fileURLToPath(import.meta.url)
const __dirname = dirname(__filename)
const PKG_ROOT = join(__dirname, '../..')

/**
 * è´¨é‡æ ‡å‡†ï¼ˆå‚è€ƒ Meta TestGen-LLM è®ºæ–‡ï¼‰
 * Reference: https://arxiv.org/pdf/2402.09171
 */
const QUALITY_STANDARDS = {
  minBuildSuccess: 0.75,    // 75% æ„å»ºæˆåŠŸï¼ˆMeta æ ‡å‡†ï¼‰
  minTestPass: 0.57,        // 57% æµ‹è¯•é€šè¿‡ï¼ˆMeta æ ‡å‡†ï¼‰
  minCoverageIncrease: 0.25, // 25% è¦†ç›–ç‡æå‡ï¼ˆMeta æ ‡å‡†ï¼‰
  maxIterations: 3,         // æœ€å¤§è¿­ä»£æ¬¡æ•°
  temperature: 0.4,         // Meta å‘ç°: 0.4 æ¯” 0.0 æˆåŠŸç‡é«˜ 25% (Table 4)
  samplesPerIteration: 1    // æ¯æ¬¡è¿­ä»£ç”Ÿæˆçš„æ ·æœ¬æ•°ï¼ˆå¯æ‰©å±•ä¸º N-sampleï¼‰
} as const

/**
 * Shellæ‰§è¡Œé€‰é¡¹
 */
interface ShellOptions {
  captureStdout?: boolean
  cwd?: string
  env?: Record<string, string>
}

/**
 * æ‰§è¡Œå‘½ä»¤
 */
function sh(cmd: string, args: string[], options: ShellOptions = {}): Promise<string | null> {
  return new Promise((resolve, reject) => {
    const stdio: StdioOptions = options.captureStdout ? ['inherit', 'pipe', 'inherit'] : 'inherit'
    const child: ChildProcess = spawn(cmd, args, { 
      stdio, 
      cwd: options.cwd || process.cwd(),
      env: options.env || process.env as Record<string, string>
    })
    
    const chunks: Buffer[] = []
    if (options.captureStdout && child.stdout) {
      child.stdout.on('data', (d: Buffer) => chunks.push(Buffer.from(d)))
    }
    
    child.on('close', (code: number | null) => {
      if (code === 0) {
        const output = options.captureStdout ? Buffer.concat(chunks).toString('utf8') : null
        resolve(output)
      } else {
        reject(new Error(`${cmd} exited ${code}`))
      }
    })
    child.on('error', reject)
  })
}

/**
 * Jest è¦†ç›–ç‡æ‘˜è¦æ¥å£
 */
interface CoverageSummary {
  total?: {
    lines?: { pct?: number }
    statements?: { pct?: number }
    functions?: { pct?: number }
    branches?: { pct?: number }
  }
}

/**
 * è¯»å–è¦†ç›–ç‡
 */
function readCoverageSummary(): CoverageSummary | null {
  const path = 'coverage/coverage-summary.json'
  if (!existsSync(path)) return null
  try { 
    return JSON.parse(readFileSync(path, 'utf8')) as CoverageSummary
  } catch { 
    return null 
  }
}

function getCoveragePercent(summary: CoverageSummary | null): number {
  if (!summary || !summary.total) return 0
  return summary.total.lines?.pct ?? 0
}

/**
 * è´¨é‡è¯„ä¼°ç»“æœ
 */
interface QualityEvaluation {
  buildSuccess: boolean
  testPass: boolean
  coverageIncrease: number
  passesStandard: boolean
  feedback: string[]
  telemetry: {
    iteration: number
    timestamp: string
    buildTimeMs: number
    testTimeMs: number
    temperature: number
    coverageBefore: number
    coverageAfter: number
    totalTimeMs: number
    passesStandard: boolean
  }
}

/**
 * è¯„ä¼°æµ‹è¯•è´¨é‡ï¼ˆMeta Filter Pipelineï¼‰
 * Reference: Section 3.1 - Build, Run, Coverage filters
 */
async function evaluateQuality(beforeCov: number, iteration: number): Promise<QualityEvaluation> {
  const startTime = Date.now()
  
  const quality: QualityEvaluation = {
    buildSuccess: false,
    testPass: false,
    coverageIncrease: 0,
    passesStandard: false,
    feedback: [],
    // ğŸ†• Meta é£æ ¼çš„é¥æµ‹æ•°æ®
    telemetry: {
      iteration,
      timestamp: new Date().toISOString(),
      buildTimeMs: 0,
      testTimeMs: 0,
      temperature: QUALITY_STANDARDS.temperature,
      coverageBefore: 0,
      coverageAfter: 0,
      totalTimeMs: 0,
      passesStandard: false
    }
  }
  
  // 1. æ£€æŸ¥æ˜¯å¦æ„å»ºæˆåŠŸ (Build Filter)
  const buildStart = Date.now()
  try {
    await sh('npx', ['tsc', '--noEmit'])
    quality.buildSuccess = true
    quality.telemetry.buildTimeMs = Date.now() - buildStart
  } catch {
    quality.feedback.push('Build failed: TypeScript compilation errors')
    quality.telemetry.buildTimeMs = Date.now() - buildStart
    return quality
  }
  
  // 2. æ£€æŸ¥æµ‹è¯•æ˜¯å¦é€šè¿‡ (Run Filter)
  const testStart = Date.now()
  try {
    await sh('npx', ['jest', '--passWithNoTests'])
    quality.testPass = true
    quality.telemetry.testTimeMs = Date.now() - testStart
  } catch {
    quality.feedback.push('Tests failed: Some tests are not passing')
    quality.telemetry.testTimeMs = Date.now() - testStart
    // ç»§ç»­ï¼Œä¸ returnï¼Œå› ä¸ºå¯èƒ½è¦†ç›–ç‡æœ‰æå‡
  }
  
  // 3. æ£€æŸ¥è¦†ç›–ç‡æ˜¯å¦æå‡ (Coverage Filter)
  const afterCov = getCoveragePercent(readCoverageSummary())
  quality.coverageIncrease = afterCov - beforeCov
  quality.telemetry.coverageBefore = beforeCov
  quality.telemetry.coverageAfter = afterCov
  
  if (quality.coverageIncrease < QUALITY_STANDARDS.minCoverageIncrease) {
    quality.feedback.push(`Coverage increase ${quality.coverageIncrease.toFixed(2)}% < required ${QUALITY_STANDARDS.minCoverageIncrease}%`)
  }
  
  // 4. åˆ¤æ–­æ˜¯å¦æ»¡è¶³æ ‡å‡†ï¼ˆå‚è€ƒ Meta çš„è¿‡æ»¤å™¨ç®¡é“ï¼‰
  quality.passesStandard = (
    quality.buildSuccess &&
    quality.testPass &&
    quality.coverageIncrease >= QUALITY_STANDARDS.minCoverageIncrease
  )
  
  quality.telemetry.totalTimeMs = Date.now() - startTime
  quality.telemetry.passesStandard = quality.passesStandard
  
  return quality
}

/**
 * è®¡ç®—å€™é€‰æµ‹è¯•çš„ç»¼åˆè¯„åˆ†ï¼ˆç”¨äº N-Sample é€‰æ‹©ï¼‰
 * Meta ç­–ç•¥: ç»¼åˆè€ƒè™‘æ„å»ºã€æµ‹è¯•ã€è¦†ç›–ç‡ä¸‰ä¸ªç»´åº¦
 */
function calculateCandidateScore(quality: QualityEvaluation): number {
  let score = 0
  
  // 1. æ„å»ºæˆåŠŸ (æƒé‡: 40%) - æœ€åŸºç¡€
  if (quality.buildSuccess) {
    score += 40
  }
  
  // 2. æµ‹è¯•é€šè¿‡ (æƒé‡: 30%) - æ¬¡é‡è¦
  if (quality.testPass) {
    score += 30
  }
  
  // 3. è¦†ç›–ç‡å¢é‡ (æƒé‡: 30%) - æœ€ç»ˆç›®æ ‡
  // å½’ä¸€åŒ–åˆ° 0-30 åˆ†
  const covScore = Math.min(quality.coverageIncrease / QUALITY_STANDARDS.minCoverageIncrease, 1) * 30
  score += covScore
  
  return score
}

/**
 * åé¦ˆä¿¡æ¯
 */
interface FeedbackInfo {
  iteration: number
  timestamp: string
  issues: string[]
  suggestions: string[]
}

/**
 * æ”¶é›†æ”¹è¿›åé¦ˆ
 */
async function collectFeedback(quality: QualityEvaluation, iteration: number): Promise<FeedbackInfo> {
  const feedback: FeedbackInfo = {
    iteration,
    timestamp: new Date().toISOString(),
    issues: quality.feedback,
    suggestions: []
  }
  
  // åŸºäºé—®é¢˜ç”Ÿæˆå»ºè®®
  if (!quality.buildSuccess) {
    feedback.suggestions.push('Fix TypeScript errors before generating tests')
    feedback.suggestions.push('Check for missing imports or type definitions')
  }
  
  if (!quality.testPass) {
    feedback.suggestions.push('Review test assertions and expected values')
    feedback.suggestions.push('Check for async/await issues in tests')
    feedback.suggestions.push('Verify mock setup is correct')
  }
  
  if (quality.coverageIncrease < QUALITY_STANDARDS.minCoverageIncrease) {
    feedback.suggestions.push('Add more test cases for uncovered branches')
    feedback.suggestions.push('Test edge cases and error conditions')
    feedback.suggestions.push('Increase assertion coverage')
  }
  
  return feedback
}

/**
 * è¿­ä»£æ”¹è¿›é€‰é¡¹
 */
interface IterativeImproveOptions {
  targetFunctions?: string[]
  reportPath?: string
  maxIterations?: number
  samplesPerIteration?: number
}

/**
 * å€™é€‰æ ·æœ¬
 */
interface CandidateSample {
  sampleIdx: number
  quality: QualityEvaluation
  score: number
}

/**
 * è¿­ä»£æ”¹è¿›ä¸»å¾ªç¯ï¼ˆMeta TestGen-LLM é£æ ¼ï¼‰
 */
export async function iterativeImprove(options: IterativeImproveOptions = {}): Promise<void> {
  const {
    reportPath = 'reports/ut_scores.md',
    maxIterations = QUALITY_STANDARDS.maxIterations,
    samplesPerIteration = QUALITY_STANDARDS.samplesPerIteration  // ğŸ†• N-Sample Generation
  } = options
  
  console.log('ğŸ”„ Starting iterative improvement (Meta TestGen-LLM style)...\n')
  console.log(`ğŸ“Š Quality Standards:`)
  console.log(`   - Build Success: ${QUALITY_STANDARDS.minBuildSuccess * 100}%`)
  console.log(`   - Test Pass: ${QUALITY_STANDARDS.minTestPass * 100}%`)
  console.log(`   - Coverage Increase: ${QUALITY_STANDARDS.minCoverageIncrease}%`)
  console.log(`   - Max Iterations: ${maxIterations}`)
  console.log(`   - Samples Per Iteration: ${samplesPerIteration} ${samplesPerIteration > 1 ? '(N-Sample Mode ğŸ²)' : ''}\n`)
  
  const beforeCov = getCoveragePercent(readCoverageSummary())
  console.log(`ğŸ“ˆ Initial Coverage: ${beforeCov.toFixed(2)}%\n`)
  
  let iteration = 1
  let quality: QualityEvaluation | null = null
  const feedbackHistory: FeedbackInfo[] = []
  
  while (iteration <= maxIterations) {
    console.log(`\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
    console.log(`ğŸ”„ Iteration ${iteration}/${maxIterations}`)
    console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n`)
    
    // 1. ç”Ÿæˆæµ‹è¯•ï¼ˆä½¿ç”¨ä¹‹å‰çš„ feedbackï¼‰
    console.log(`ğŸ¤– Generating tests ${samplesPerIteration > 1 ? `(${samplesPerIteration} samples)` : ''}...`)
    
    try {
      if (feedbackHistory.length > 0) {
        // å°† feedback å†™å…¥ hints æ–‡ä»¶
        const hintsContent = feedbackHistory.map((fb) => 
          `## Iteration ${fb.iteration} Feedback:\n` +
          `Issues:\n${fb.issues.map((i: string) => `- ${i}`).join('\n')}\n` +
          `Suggestions:\n${fb.suggestions.map((s: string) => `- ${s}`).join('\n')}`
        ).join('\n\n')
        
        writeFileSync('reports/improvement_hints.txt', hintsContent, 'utf-8')
        console.log(`ğŸ’¡ Using feedback from ${feedbackHistory.length} previous iteration(s)`)
      }
      
      //  N-Sample Generation: ç”Ÿæˆå¤šä¸ªå€™é€‰ï¼Œé€‰æ‹©æœ€ä½³
      if (samplesPerIteration > 1) {
        const candidates: CandidateSample[] = []
        
        for (let sampleIdx = 0; sampleIdx < samplesPerIteration; sampleIdx++) {
          console.log(`\n   ğŸ² Sample ${sampleIdx + 1}/${samplesPerIteration}...`)
          
          // ç”Ÿæˆå€™é€‰æµ‹è¯•
          await sh('node', [
            join(PKG_ROOT, 'lib/workflows/batch.mjs'),
            null, // priority
            '10', // limit
            '0',  // skip
            reportPath
          ])
          
          // ç«‹å³è¯„ä¼°æ­¤å€™é€‰çš„è´¨é‡
          const candidateQuality = await evaluateQuality(beforeCov, iteration)
          
          // ä¿å­˜å€™é€‰ç»“æœåˆ°ä¸´æ—¶ç›®å½•
          const candidateDir = `reports/candidates/iter${iteration}_sample${sampleIdx}`
          await sh('mkdir', ['-p', candidateDir], {})
          await sh('cp', ['-r', 'coverage', `${candidateDir}/`], {}).catch(() => {})
          
          candidates.push({
            sampleIdx,
            quality: candidateQuality,
            score: calculateCandidateScore(candidateQuality)
          })
          
          console.log(`      Build: ${candidateQuality.buildSuccess ? 'âœ…' : 'âŒ'}, ` +
                     `Pass: ${candidateQuality.testPass ? 'âœ…' : 'âŒ'}, ` +
                     `Cov: ${candidateQuality.coverageIncrease.toFixed(2)}%, ` +
                     `Score: ${calculateCandidateScore(candidateQuality).toFixed(2)}`)
        }
        
        // é€‰æ‹©æœ€ä½³å€™é€‰
        candidates.sort((a, b) => b.score - a.score)
        const bestCandidate = candidates[0]
        
        if (!bestCandidate) {
          throw new Error('No valid candidate samples generated')
        }
        
        console.log(`\n   âœ¨ Best sample: #${bestCandidate.sampleIdx + 1} (score: ${bestCandidate.score.toFixed(2)})`)
        
        // æ¢å¤æœ€ä½³å€™é€‰çš„è¦†ç›–ç‡æ•°æ®
        const bestCandidateDir = `reports/candidates/iter${iteration}_sample${bestCandidate.sampleIdx}`
        await sh('cp', ['-r', `${bestCandidateDir}/coverage`, '.'], {}).catch(() => {})
        
        quality = bestCandidate.quality
      } else {
        // å•æ ·æœ¬æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        await sh('node', [
          join(PKG_ROOT, 'lib/workflows/batch.mjs'),
          'null', // priority
          '10', // limit
          '0',  // skip
          reportPath
        ], {})
      }
    } catch (err: unknown) {
      const error = err as Error
      console.error(`âŒ Generation failed: ${error?.message || String(err)}`)
      break
    }
    
    // 2. è¯„ä¼°è´¨é‡ï¼ˆMeta Filter Pipelineï¼‰
    // N-Sample æ¨¡å¼ä¸‹å·²ç»åœ¨å€™é€‰é€‰æ‹©æ—¶è¯„ä¼°è¿‡äº†
    if (samplesPerIteration === 1) {
      console.log('\nğŸ“Š Evaluating quality...')
      quality = await evaluateQuality(beforeCov, iteration)
    } else {
      console.log('\nğŸ“Š Final quality (best sample):')
    }
    
    console.log(`   Build: ${quality.buildSuccess ? 'âœ…' : 'âŒ'} (${quality.telemetry.buildTimeMs}ms)`)
    console.log(`   Tests Pass: ${quality.testPass ? 'âœ…' : 'âŒ'} (${quality.telemetry.testTimeMs}ms)`)
    console.log(`   Coverage: ${quality.coverageIncrease.toFixed(2)}% ${quality.coverageIncrease >= QUALITY_STANDARDS.minCoverageIncrease ? 'âœ…' : 'âŒ'} (${quality.telemetry.coverageBefore.toFixed(2)}% â†’ ${quality.telemetry.coverageAfter.toFixed(2)}%)`)
    
    // 3. æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ ‡å‡†
    if (quality.passesStandard) {
      console.log(`\nğŸ‰ Quality standard met!`)
      console.log(`   Final coverage: ${(beforeCov + quality.coverageIncrease).toFixed(2)}%`)
      console.log(`   Iterations used: ${iteration}/${maxIterations}`)
      break
    }
    
    // 4. æ”¶é›†åé¦ˆ
    const feedback = await collectFeedback(quality, iteration)
    feedbackHistory.push(feedback)
    
    console.log(`\nğŸ’¬ Feedback for next iteration:`)
    feedback.issues.forEach(issue => console.log(`   âš ï¸  ${issue}`))
    feedback.suggestions.forEach(sug => console.log(`   ğŸ’¡ ${sug}`))
    
    // 5. æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
    if (iteration >= maxIterations) {
      console.log(`\nâ±ï¸  Reached max iterations (${maxIterations})`)
      if (quality) {
        console.log(`   Final quality:`)
        console.log(`   - Build: ${quality.buildSuccess ? 'Pass' : 'Fail'}`)
        console.log(`   - Tests: ${quality.testPass ? 'Pass' : 'Fail'}`)
        console.log(`   - Coverage: +${quality.coverageIncrease.toFixed(2)}%`)
      }
      break
    }
    
    iteration++
  }
  
  // ç”Ÿæˆæ”¹è¿›æŠ¥å‘Šï¼ˆMeta é£æ ¼ - åŒ…å«è¯¦ç»†é¥æµ‹ï¼‰
  const report = {
    success: quality?.passesStandard || false,
    iterations: iteration,
    initialCoverage: beforeCov,
    finalCoverage: beforeCov + (quality?.coverageIncrease || 0),
    improvement: quality?.coverageIncrease || 0,
    feedbackHistory,
    // ğŸ†• Meta é£æ ¼çš„é¥æµ‹æ±‡æ€»
    telemetry: {
      temperature: QUALITY_STANDARDS.temperature,
      maxIterations: maxIterations,
      qualityStandards: {
        minBuildSuccess: QUALITY_STANDARDS.minBuildSuccess,
        minTestPass: QUALITY_STANDARDS.minTestPass,
        minCoverageIncrease: QUALITY_STANDARDS.minCoverageIncrease
      },
      iterationDetails: feedbackHistory.map(fb => ({
        iteration: fb.iteration,
        timestamp: fb.timestamp,
        issues: fb.issues,
        suggestions: fb.suggestions
      })),
      finalQuality: quality?.telemetry || null
    },
    // è®ºæ–‡å¼•ç”¨
    reference: 'Meta TestGen-LLM (2024) - https://arxiv.org/pdf/2402.09171'
  }
  
  writeFileSync('reports/improvement_report.json', JSON.stringify(report, null, 2), 'utf-8')
  console.log(`\nğŸ“„ Full report saved: reports/improvement_report.json`)
  console.log(`   Reference: Meta TestGen-LLM - https://arxiv.org/pdf/2402.09171`)
  
  return report
}

/**
 * CLI å…¥å£
 */
async function main(argv: string[] = process.argv): Promise<void> {
  const args = argv.slice(2)
  const reportPath = args[0]
  const maxIterations = parseInt(args[1]) || QUALITY_STANDARDS.maxIterations
  
  try {
    await iterativeImprove({
      reportPath,
      maxIterations
    })
  } catch (err) {
    console.error(`âŒ Iterative improvement failed: ${err.message}`)
    process.exit(1)
  }
}

if (import.meta.url === `file://${process.argv[1]}`) {
  main()
}

